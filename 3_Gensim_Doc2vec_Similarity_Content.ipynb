{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim - Doc2vec untuk Similarity Content\n",
    "Similarity Content menggunakan vector merupakan cara sederhana untuk mendapatkan kesamaan dari sebuah artikel.\n",
    "Dalam kasus ini saya akan menggunakan hasil scraping data google news indonesia berjumlah 77 documents saja.\n",
    "\n",
    "Adapun module yang digunakan adalah menggunkan gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirement\n",
    "- Gensim 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kode Sederhana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import gensim\n",
    "from pprint import pprint\n",
    "import multiprocessing\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stoplist():\n",
    "    stop = []\n",
    "    for line in open('stopwords.txt','rU'):\n",
    "        stop += line.replace(',','').split()\n",
    "    return stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782\n",
      "['ada', 'adalah', 'adanya', 'adapun', 'agak', 'agaknya', 'agar', 'akan', 'akankah', 'akhir', 'akhiri', 'akhirnya', 'aku', 'akulah', 'amat', 'amatlah', 'anda', 'andalah', 'antar', 'antara']\n"
     ]
    }
   ],
   "source": [
    "stopwords = get_stoplist()\n",
    "print(len(stopwords))\n",
    "print(stopwords[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/gensim/models/phrases.py:274: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    }
   ],
   "source": [
    "dirname = 'google_news'\n",
    "documents_file = os.listdir(dirname)\n",
    "\n",
    "documents = []\n",
    "\n",
    "for fname in documents_file:\n",
    "    f = open(os.path.join(dirname,fname),'rU')\n",
    "    content = f.read().decode('utf-8').lower()\n",
    "    words_split = re.findall(r\"[\\w']+|[.,!?;]\",content) # memotong kalimat berdasarkan punctuation\n",
    "    words_split = [word for word in words_split if word not in stopwords]\n",
    "\n",
    "    phrases = gensim.models.phrases.Phrases(words_split,min_count=20, threshold=100)\n",
    "    bigram = gensim.models.phrases.Phraser(phrases)\n",
    "    trigram = gensim.models.phrases.Phrases(bigram[words_split],min_count=20, threshold=100)\n",
    "    for idx in range(len(words_split)):\n",
    "        for token in bigram[words_split[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a bigram, add to document.\n",
    "#                 print(words_split[idx])\n",
    "#                 words_split[idx].append(token)\n",
    "                words_split[idx] += token\n",
    "            \n",
    "    for idx in range(len(words_split)):\n",
    "        for token in trigram[words_split[idx]]:\n",
    "            if '_' in token:\n",
    "                # Token is a trigram, add to document.\n",
    "#                 words_split[idx].append(token)\n",
    "                words_split[idx] += token\n",
    "#     print(words_split)\n",
    "    filtered_tokens = []\n",
    "    for token in words_split:\n",
    "        if re.search('[a-zA-Z]', token): # filter hanya huruf saja\n",
    "            filtered_tokens.append(token)\n",
    "    \n",
    "    title = fname.replace('.txt','')\n",
    "    documents.append(TaggedDocument(filtered_tokens,[title]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"'Formasi Tiga Bek Arsenal Belum Sempurna'\"]\n"
     ]
    }
   ],
   "source": [
    "pprint(documents[:1][0].tags)\n",
    "# pprint(documents[4].words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'arsene', u'wenger', u'menerapkan', u'formasi', u'bek', u'memetik', u'kemenangan', u'manchester', u'united', u'the', u'professor', u'bersikeras', u'mengubah', u'skema', u'bermainnya', u'pasca', u'kekalahan', u'crystal', u'palace', u'arsenal', u'mengubah', u'gaya', u'bermainnya', u'formasi', u'bek', u'ditinggalkan', u'arsene', u'wenger', u'pertandingan', u'wenger', u'menerapkan', u'formasi', u'bek', u'membawa', u'arsenal', u'menang', u'kali', u'menelan', u'kekalahan', u'liga', u'inggris', u'kemenangan', u'terbaru', u'melakoni', u'pertandingan', u'melawan', u'the', u'red', u'devils', u'skor', u'arsenal', u'menang', u'berkat', u'gol', u'dibukukan', u'granit', u'xhaka', u'danny', u'welbeck', u'wenger', u'menilai', u'tim', u'besutannya', u'bertahan', u'stabil', u'bermain', u'bek', u'laga', u'melawan', u'mu', u'babak', u'laga', u'emirates', u'stadium', u'kestabilan', u'bertahab', u'kebobolan', u'wenger', u'sky', u'sports', u'sempurna', u'fokus', u'menggalang', u'pertahanan', u'dibandingkan', u'melawan', u'mu', u'wenger', u'kesempatan', u'bermain', u'lauren', u'koscielny', u'rob', u'holding', u'nacho', u'monreal', u'tampil', u'satunya', u'cela', u'kesalahan']\n"
     ]
    }
   ],
   "source": [
    "print(documents[:2][0].words[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "model = Doc2Vec(dm=0, dbow_words=1, size=100, window=8, min_count=20, iter=100, workers=cores, sample=1e-4, negative=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n2,w8,mc20,s0.0001,t4)\n"
     ]
    }
   ],
   "source": [
    "model.scan_vocab(documents,update=False)\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n2,w8,mc20,s0.0001,t4)\n"
     ]
    }
   ],
   "source": [
    "model.build_vocab(documents,update=False)\n",
    "print(str(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.34 s, sys: 1.38 s, total: 5.72 s\n",
      "Wall time: 3.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "410344"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time model.train(documents, total_examples=model.corpus_count, epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow+w,d100,n2,w8,mc20,s0.0001,t4)\n",
      "[('Ini Alasan Xiaomi Mi 6 Tiru iPhone 7', 0.9499949216842651),\n",
      " ('Mengapa Xiaomi Mi 6 Harus Mengikuti Langkah iPhone 7? - Kompas.com',\n",
      "  0.906842827796936),\n",
      " ('Smartphone Baru ASUS X00ID Muncul di GFXBench dengan Dual-camera',\n",
      "  0.865568995475769),\n",
      " ('Qualcomm Sudah Daftarkan Snapdragon 845 di Website Resminya',\n",
      "  0.7996097803115845),\n",
      " ('Resmi Masuk Negara Turki, iPhone 7 Tembus Harga Rp 16 Jutaan Dan Menjadi Rekor Harga Tertinggi Hingga Saat Ini',\n",
      "  0.7913281917572021),\n",
      " ('ASUS Zenfone X015D Muncul di GFXBench Usung Chipset MediaTek dan RAM 3GB',\n",
      "  0.7558867931365967),\n",
      " ('Samsung Galaxy J7 (2017) Muncul Lagi di GFXBench dengan Spesifikasi Berbeda',\n",
      "  0.7387588024139404),\n",
      " ('Nokia 3310 Akan Dipasarkan Secara Global', 0.6635607481002808),\n",
      " ('Nokia 3310 Terbaru Mulai Dikirim', 0.6366978883743286),\n",
      " ('Negara Mana yang Jual iPhone 7 Termahal dan Termurah?', 0.6267486810684204)]\n"
     ]
    }
   ],
   "source": [
    "print(str(model))\n",
    "pprint(model.docvecs.most_similar(positive=[\"5 Kesamaan Xiaomi Mi 6 dan iPhone 7 Plus\"], topn=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Begini cerita busa sabun yang dikira hujan salju di Jalan Sudirman',\n",
       "  0.7201998233795166),\n",
       " ('Benda Mirip Salju di Jalan Jenderal Sudirman Sabun untuk Melunakkan Tanah',\n",
       "  0.6918919086456299),\n",
       " ('Penjelasan MRT Jakarta Soal Buih Mirip Salju di Jalan Sudirman',\n",
       "  0.6918407678604126),\n",
       " ('Dari Mana Asal Busa yang Dikira Salju di Jalan Sudirman? - Kompas.com',\n",
       "  0.6818339824676514),\n",
       " ('Memastikan Bukan Salju di Jalan Jendral Sudirman, Ini Penjelasan PT MRT Jakarta - Wartakota',\n",
       "  0.6708693504333496),\n",
       " ('Akibat Kecerobohan Karyawan, Busa di Sepanjang Jalan di Jakarta Dikira Salju - eKoran.Net',\n",
       "  0.6666598320007324),\n",
       " ('Pemprov DKI Selidiki Keamanan Busa Proyek MRT yang Menghebohkan',\n",
       "  0.6551097631454468),\n",
       " ('Gempar Hujan Salju di Jakarta, PT MRT Minta Maaf', 0.647350013256073),\n",
       " ('Petugas PT MRT Bersihkan Buih Mirip Salju di Jalan Sudirman',\n",
       "  0.6446686387062073),\n",
       " ('Heboh Turun Salju di Jakarta Ternyata Cuma Cairan Sabun - Tribun Jabar',\n",
       "  0.6381543874740601)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_search = '''busa sabun jalan sudirman'''\n",
    "inferred_vector = model.infer_vector(text_search.lower().split())\n",
    "model.docvecs.most_similar([inferred_vector], topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -2.25954324e-01,   1.23186693e-01,  -8.79537761e-02,\n",
       "         5.32568574e-01,  -5.72701871e-01,   4.46958281e-02,\n",
       "        -4.84704703e-01,  -1.41727492e-01,  -3.09160829e-01,\n",
       "        -4.09467816e-01,  -9.00486633e-02,   1.73302397e-01,\n",
       "        -1.49284795e-01,   1.00194395e-01,   4.47514504e-01,\n",
       "         1.63158298e-01,   3.00338954e-01,  -5.69132119e-02,\n",
       "        -4.92458679e-02,   1.90102588e-02,   6.97194831e-04,\n",
       "        -2.40246728e-01,  -1.85915813e-01,   5.26626185e-02,\n",
       "         2.70957738e-01,   1.77305005e-02,   1.61580682e-01,\n",
       "         1.84968039e-01,  -7.90281072e-02,   5.15848219e-01,\n",
       "         8.77135277e-01,   5.90857714e-02,  -3.30129974e-02,\n",
       "         4.39862847e-01,  -4.59410280e-01,   3.97212803e-01,\n",
       "        -1.82566181e-01,  -3.90071571e-02,   8.50754321e-01,\n",
       "         6.19083226e-01,  -2.20257878e-01,   4.85509992e-01,\n",
       "        -4.70316187e-02,   3.62264849e-02,  -5.28140925e-02,\n",
       "         1.85851693e-01,   3.31997097e-01,   3.08416873e-01,\n",
       "         2.81796247e-01,  -2.29108453e-01,   2.90523082e-01,\n",
       "        -1.10582218e-01,   8.34555551e-02,   5.78473434e-02,\n",
       "        -5.44825256e-01,   2.52919674e-01,  -2.93720532e-02,\n",
       "         4.86641526e-01,   4.98908997e-01,  -2.83786714e-01,\n",
       "        -1.07791714e-01,  -2.18909398e-01,   4.54612672e-01,\n",
       "         2.85787493e-01,   6.09603405e-01,   9.43249613e-02,\n",
       "        -4.28612716e-02,  -3.47521335e-01,   3.11856925e-01,\n",
       "        -1.28419340e-01,  -9.75396574e-01,   2.30593786e-01,\n",
       "        -8.06702748e-02,  -5.59487760e-01,   3.24030042e-01,\n",
       "        -5.35586655e-01,   4.53751713e-01,   2.61457950e-01,\n",
       "        -1.12564512e-01,  -2.81359881e-01,  -2.31419317e-02,\n",
       "        -4.42185968e-01,   7.94908702e-02,  -1.51606083e-01,\n",
       "         1.00206710e-01,  -5.68046212e-01,   1.28284603e-01,\n",
       "        -7.04542339e-01,  -2.00651074e-03,  -1.44865111e-01,\n",
       "        -4.26971763e-01,   3.05639327e-01,  -2.99131244e-01,\n",
       "         3.35587673e-02,   3.14426810e-01,   4.60964739e-01,\n",
       "        -5.07430255e-01,   1.56259283e-01,  -3.53760362e-01,\n",
       "        -2.15146452e-01], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.docvecs['5 Kesamaan Xiaomi Mi 6 dan iPhone 7 Plus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
